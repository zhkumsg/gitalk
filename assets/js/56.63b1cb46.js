(window.webpackJsonp=window.webpackJsonp||[]).push([[56],{167:function(t,e,s){"use strict";s.r(e);var n=s(0),a=Object(n.a)({},(function(){var t=this,e=t.$createElement,s=t._self._c||e;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"网页爬虫的实现与注意事项"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#网页爬虫的实现与注意事项"}},[t._v("#")]),t._v(" 网页爬虫的实现与注意事项")]),t._v(" "),s("p",[t._v("互联网每天都会产生非常多的信息，其中有不少的数据值得我们收集，我们往往是使用人工的方式去记录下来，但是我想说的是")]),t._v(" "),s("p",[t._v("重复的事就应该交给电脑处理")]),t._v(" "),s("p",[t._v("刚好前几天帮朋友做了一个爬虫小工具，借此机会把实现过程和注意事项分享一下")]),t._v(" "),s("ul",[s("li",[t._v("需求：通过上传Excel文件，读取Excel中的帖子链接，抓取帖子的 "),s("code",[t._v("标题，内容，图片个数，点击量和评论数")])])]),t._v(" "),s("p",[t._v("想到既然要做爬虫，第一考虑自然就是 "),s("code",[t._v("python")]),t._v(" ， "),s("em",[t._v("详细见"),s("a",{attrs:{href:"https://www.jianshu.com/p/52de49932327",target:"_blank",rel:"noopener noreferrer"}},[t._v("《关于python模拟浏览器行为》"),s("OutboundLink")],1)]),t._v(" 。python天生对爬虫友好，利用 "),s("code",[t._v("requests和BeautifulSoup")]),t._v(" 这两个模块，可以实现大部分的功能，但由于近期一直在做nodejs和项目，所以这里我们以 "),s("code",[t._v("nodejs")]),t._v(" 为例。")]),t._v(" "),s("ul",[s("li",[t._v("目标：创建一个 "),s("code",[t._v("站点")]),t._v(" ，接受用户 "),s("code",[t._v("上传")]),t._v(" 的文件， "),s("code",[t._v("解析")]),t._v(" 并实时 "),s("code",[t._v("爬取")]),t._v(" 特定信息，保持数据到 "),s("code",[t._v("数据库")]),t._v(" 中，并提供 "),s("code",[t._v("导出")]),t._v(" 功能。")])]),t._v(" "),s("p",[s("img",{attrs:{src:"https://upload-images.jianshu.io/upload_images/13908708-189f4ab2fdfb9313.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240",alt:"效果图"}})]),t._v(" "),s("p",[s("strong",[t._v("实现过程")])]),t._v(" "),s("ul",[s("li",[s("code",[t._v("需求分析")])])]),t._v(" "),s("p",[t._v("从上文中我们知道了大体需要实现 "),s("code",[t._v("导入excel、识别url、抓取url信息")]),t._v(" 的功能。\n既然要实现这种交互式的功能，做可执行程序或网站都是一个可行方案，从持续化更新角度出发，我们选用了开发web的方向，也就是搭建一个外网可访问的web站点。\n其次， "),s("code",[t._v("导入excel")]),t._v(" 涉及到_文件上传和io操作_，为了美观我们使用了 "),s("code",[t._v("Bootstrap")]),t._v(" 框架做ui展示，后端使用 "),s("code",[t._v("nodejs")]),t._v(" 接收文件。\n接收到文件后，我们需要识别文件中的帖子url信息，这就需要我们去打开刚刚上传的文件了，这里使用npm模块 "),s("code",[t._v("XLSX")]),t._v(" 去识别。\n当读取完excel信息后，把url存放到队列中，通过在后端轮询队列发起http请求，不停爬取帖子信息，并实时通知前端页面当前进度和抓取内容，所以这里又用到了 "),s("code",[t._v("http/request")]),t._v(" 和 "),s("code",[t._v("websocket")]),t._v(" 。\n抓取到信息后，还需要持久化，可以考虑记录到文本文件或数据库，这里选用数据库，所以还需要 "),s("code",[t._v("database")]),t._v(" 相关。\n最后，数据爬取完整后，提供一个导出功能，导出使用前端导出的方式，即生成table，调用第三方插件 "),s("code",[t._v("导出excel")]),t._v(" 。")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("技术栈")])])]),t._v(" "),s("table",[s("thead",[s("tr",[s("th",{staticStyle:{"text-align":"center"}},[t._v("技术")]),t._v(" "),s("th",{staticStyle:{"text-align":"center"}},[t._v("版本")]),t._v(" "),s("th",{staticStyle:{"text-align":"center"}},[t._v("描述")])])]),t._v(" "),s("tbody",[s("tr",[s("td",{staticStyle:{"text-align":"center"}},[t._v("html")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("5")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("页面")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"center"}},[t._v("js")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("ECMCScript2015")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("脚本")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"center"}},[t._v("css")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("3")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("样式")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"center"}},[t._v("nodejs")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("v10.15.1")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("后端语言")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"center"}},[t._v("request")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("v2.88.0")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("http请求")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"center"}},[t._v("xlsx")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("v0.14.3")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("识别excel")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"center"}},[t._v("multiparty")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("v4.2.1")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("表单上传")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"center"}},[t._v("nodejs-websocket")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("v1.7.2")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("socket通讯")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"center"}},[t._v("jh-common-dataaccess")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("v0.0.7")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("数据库底层")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"center"}},[t._v("cheerio")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("v1.0.0-rc.3")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("html识别")])]),t._v(" "),s("tr",[s("td",{staticStyle:{"text-align":"center"}},[t._v("iconv-lite")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("v0.5.0")]),t._v(" "),s("td",{staticStyle:{"text-align":"center"}},[t._v("字符串编码")])])])]),t._v(" "),s("ul",[s("li",[s("code",[t._v("数据来源")])])]),t._v(" "),s("p",[t._v("做爬虫程序，如何获取数据至关重要。在朋友给的参考页面上，需要获取到 "),s("code",[t._v("帖子标题、帖子内容、帖子图片数、评论数和点击数")]),t._v(" 等，通过查看网络请求发现， "),s("code",[t._v("帖子标题、内容和图片")]),t._v(" 是以 "),s("code",[t._v("html")]),t._v(" 的形式展示，而 "),s("code",[t._v("评论数")]),t._v(" 和 "),s("code",[t._v("点击数")]),t._v(" ，需要额外发起异步请求获取，所以接下来的事就很明确了：")]),t._v(" "),s("ol",[s("li",[t._v("解析html内容，获取标题、内容和图片数")]),t._v(" "),s("li",[t._v("研究评论数、点击数异步请求参数及数据结果")])]),t._v(" "),s("p",[t._v("经研究后发现，html通过 "),s("code",[t._v("cheerio")]),t._v(" 模块可以轻松识别")]),t._v(" "),s("div",{staticClass:"language-js extra-class"},[s("pre",{pre:!0,attrs:{class:"language-js"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" cheerio "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("require")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'cheerio'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" Iconv "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("require")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'iconv-lite'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// body是html文档")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" $ "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" cheerio"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("load")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Iconv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("decode")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("body"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'gb2312'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("toString")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" titleTxt "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("$")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'#maxwrap-maintopic div.rconten'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 帖子标题")]),t._v("\n")])])]),s("p",[t._v("cheerio的使用和JQuery非常相像。")]),t._v(" "),s("p",[t._v("而对于获取评论数和点击数却需要注意点细节，其中获取html的url中，会带有帖子的主键，查询点击数评论数的时候需要带上此信息，url如下")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("https://xxx.xxx.com.cn/Detail/LoadX_Mini?topicId=帖子id\n")])])]),s("p",[t._v("发起get请求后可以拿到 "),s("code",[t._v("replys")]),t._v(" 和 "),s("code",[t._v("views")]),t._v(" ，分别代表评论数和点击数。")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("数据处理")])])]),t._v(" "),s("p",[t._v("数据是从用户上传的excel中获取帖子url列表，通过表单上传和使用 "),s("code",[t._v("xlsx")]),t._v(" 模块解析")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("const XLSX = require('xlsx');\n")])])]),s("p",[t._v("拿到需要爬取的帖子地址数组后，循环发起http请求，先获取html内容，再获取帖子评论数。发起http请求可以使用 "),s("code",[t._v("request")])]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("const request = require('request');\n\n// 配置参数\nconst options = {\n\t\tmethod: 'get',\n\t\turl: '目标url',\n};\n// 发起http请求\nrequest(options, (err, res, body)=>{\n  // 解析body获取读取body信息\n}};\n")])])]),s("p",[t._v("由于需要向其他服务器发起请求，所以有很多事需要注意的，比如_ "),s("code",[t._v("如何避免反爬虫机制")]),t._v(" _，后面会继续介绍。")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("数据持久化")])])]),t._v(" "),s("p",[t._v("获取到数据库，我们采用持久化到数据库的形式，我们之前就已经封装国一个数据库操作底层，支持mysql、mssql、sqlite等多种数据库操作，所以实现非常简单")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("const { DataAccess } = require('jh-common-dataaccess');\nconst { dbConfig } = require('./package.json');\n\nconst ds = new DataAccess(dbConfig);\nds.execute('sql string');\n")])])]),s("ul",[s("li",[s("code",[t._v("数据展示")])])]),t._v(" "),s("p",[t._v("既然是做web，那么自然需要做一个展示，我们通过html搭建了一个可视化界面，可以实时显示爬取进度和爬取操作，为了方便，封装了一个 "),s("code",[t._v("WebHelper")]),t._v(" 和 "),s("code",[t._v("SocketHelper")]),t._v(" ，分别提供web服务和socket服务。")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("const WebHelper = require('./helper/WebHelper');\nconst SockeHelper = require('./helper/SocketHelper');\n\n// socket服务\nconst socker = new SockeHelper();\n\n// http服务\nnew WebHelper((req, res)=>{\n  // todo 处理响应\n// 实时信息可通过socket进行广播\n})\n")])])]),s("p",[s("strong",[t._v("注意事项")])]),t._v(" "),s("ol",[s("li",[s("p",[t._v("注意字符编码，http响应的字符编码不一定符合要求，建议同意使用utf-8")])]),t._v(" "),s("li",[s("p",[t._v("注意反爬虫机制。")])])]),t._v(" "),s("p",[t._v("与天斗与地斗与反爬虫斗，其乐无穷")]),t._v(" "),s("p",[t._v("可以说做爬虫，不可避免要与反爬虫做斗争。\n"),s("code",[t._v("第一次处理")]),t._v(" ：在最开始做这个工具的时候，直接用多线程，循环很快就结束了，后台在不停的请求，测试后发现很快就返回500了，原因是目标服务器在短时间内接收到大量的请求，服务异常；\n"),s("code",[t._v("第二次处理")]),t._v(" ：使用递归模式，上一次请求完成后，等待一定时间再触发下一次请求，直到队列中没有需要爬取的url。这个方式基本解决了目标服务器奔溃的问题。然后一周的高频率爬取后，爬虫突然被限制，请求头中的信息被限制了\n"),s("code",[t._v("第三次处理")]),t._v(" ：修改请求头，随机选用 "),s("code",[t._v("User-Agent")]),t._v(" 并使用 "),s("code",[t._v("代理ip")]),t._v(" ，完美解决限制问题。\n"),s("code",[t._v("第四次处理")]),t._v(" ：发现其存在移动站点，且没加爬虫限制，决定分一半流量到其移动端站点。\n"),s("code",[t._v("第五次处理")]),t._v(" ：终究代理ip需要花钱，所以开发了一款谷歌插件，由客户端执行和服务端配合执行，形成最终结局方案。")])])}),[],!1,null,null,null);e.default=a.exports}}]);