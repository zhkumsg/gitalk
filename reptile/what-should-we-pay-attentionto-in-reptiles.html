<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>网页爬虫的实现与注意事项 | Wiki文档中心</title>
    <meta name="description" content="描述">
    <link rel="icon" href="/logo.png">
    
    <link rel="preload" href="/assets/css/0.styles.4d8ba4a7.css" as="style"><link rel="preload" href="/assets/js/app.3328e81d.js" as="script"><link rel="preload" href="/assets/js/2.c715c0f2.js" as="script"><link rel="preload" href="/assets/js/56.63b1cb46.js" as="script"><link rel="prefetch" href="/assets/js/10.abfcde09.js"><link rel="prefetch" href="/assets/js/11.3ee26f26.js"><link rel="prefetch" href="/assets/js/12.45406b92.js"><link rel="prefetch" href="/assets/js/13.7aa97305.js"><link rel="prefetch" href="/assets/js/14.34708031.js"><link rel="prefetch" href="/assets/js/15.76570f77.js"><link rel="prefetch" href="/assets/js/16.29d4e7cd.js"><link rel="prefetch" href="/assets/js/17.eda984dd.js"><link rel="prefetch" href="/assets/js/18.1bb9f9b9.js"><link rel="prefetch" href="/assets/js/19.231ae034.js"><link rel="prefetch" href="/assets/js/20.26a455ac.js"><link rel="prefetch" href="/assets/js/21.62f18186.js"><link rel="prefetch" href="/assets/js/22.177e8b0f.js"><link rel="prefetch" href="/assets/js/23.60274af5.js"><link rel="prefetch" href="/assets/js/24.0ea00a49.js"><link rel="prefetch" href="/assets/js/25.3d5be951.js"><link rel="prefetch" href="/assets/js/26.19229e66.js"><link rel="prefetch" href="/assets/js/27.6d99c0ab.js"><link rel="prefetch" href="/assets/js/28.d28de4e0.js"><link rel="prefetch" href="/assets/js/29.29379faf.js"><link rel="prefetch" href="/assets/js/3.90a63800.js"><link rel="prefetch" href="/assets/js/30.9fe6691b.js"><link rel="prefetch" href="/assets/js/31.2c753b40.js"><link rel="prefetch" href="/assets/js/32.b87ed25b.js"><link rel="prefetch" href="/assets/js/33.69099052.js"><link rel="prefetch" href="/assets/js/34.fb2e76ab.js"><link rel="prefetch" href="/assets/js/35.41f3d46b.js"><link rel="prefetch" href="/assets/js/36.78adf827.js"><link rel="prefetch" href="/assets/js/37.6cb8f1dc.js"><link rel="prefetch" href="/assets/js/38.3296535c.js"><link rel="prefetch" href="/assets/js/39.852ec6ec.js"><link rel="prefetch" href="/assets/js/4.338175e6.js"><link rel="prefetch" href="/assets/js/40.4f030cd4.js"><link rel="prefetch" href="/assets/js/41.7b948635.js"><link rel="prefetch" href="/assets/js/42.7038bdd7.js"><link rel="prefetch" href="/assets/js/43.09ba85b3.js"><link rel="prefetch" href="/assets/js/44.30c43542.js"><link rel="prefetch" href="/assets/js/45.7fc52c71.js"><link rel="prefetch" href="/assets/js/46.e57513f1.js"><link rel="prefetch" href="/assets/js/47.79ad04e1.js"><link rel="prefetch" href="/assets/js/48.806e5af9.js"><link rel="prefetch" href="/assets/js/49.1e083288.js"><link rel="prefetch" href="/assets/js/5.15ce4230.js"><link rel="prefetch" href="/assets/js/50.eef1990e.js"><link rel="prefetch" href="/assets/js/51.cdde33a8.js"><link rel="prefetch" href="/assets/js/52.bcb09293.js"><link rel="prefetch" href="/assets/js/53.87c2baec.js"><link rel="prefetch" href="/assets/js/54.4d9707e7.js"><link rel="prefetch" href="/assets/js/55.5fb2a242.js"><link rel="prefetch" href="/assets/js/57.4108fa62.js"><link rel="prefetch" href="/assets/js/58.38c656c4.js"><link rel="prefetch" href="/assets/js/59.2e9da043.js"><link rel="prefetch" href="/assets/js/6.4db8bcb4.js"><link rel="prefetch" href="/assets/js/60.62a9603a.js"><link rel="prefetch" href="/assets/js/61.70db4cce.js"><link rel="prefetch" href="/assets/js/62.c0b27237.js"><link rel="prefetch" href="/assets/js/63.a1ff59d9.js"><link rel="prefetch" href="/assets/js/64.ba32929f.js"><link rel="prefetch" href="/assets/js/65.504fa9a6.js"><link rel="prefetch" href="/assets/js/66.39a7e2d4.js"><link rel="prefetch" href="/assets/js/67.409ffc00.js"><link rel="prefetch" href="/assets/js/68.21b084fc.js"><link rel="prefetch" href="/assets/js/69.1d10efe9.js"><link rel="prefetch" href="/assets/js/7.6832275b.js"><link rel="prefetch" href="/assets/js/70.0391f331.js"><link rel="prefetch" href="/assets/js/71.af289666.js"><link rel="prefetch" href="/assets/js/72.9a8504b0.js"><link rel="prefetch" href="/assets/js/73.0d35f166.js"><link rel="prefetch" href="/assets/js/74.75cd3652.js"><link rel="prefetch" href="/assets/js/75.53679119.js"><link rel="prefetch" href="/assets/js/76.5ea9dd36.js"><link rel="prefetch" href="/assets/js/77.95fe4c15.js"><link rel="prefetch" href="/assets/js/78.aaff367b.js"><link rel="prefetch" href="/assets/js/8.3662cfcf.js"><link rel="prefetch" href="/assets/js/9.a40092b3.js">
    <link rel="stylesheet" href="/assets/css/0.styles.4d8ba4a7.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/logo.png" alt="Wiki文档中心" class="logo"> <span class="site-name can-hide">Wiki文档中心</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/introduce/" class="nav-link">指南</a></div><div class="nav-item"><a href="/sso/" class="nav-link">单点登录</a></div><div class="nav-item"><a href="/seo/" class="nav-link">服务端渲染</a></div><div class="nav-item"><a href="/linux/" class="nav-link">Linux基础</a></div><div class="nav-item"><a href="/http/" class="nav-link">解读Http</a></div><div class="nav-item"><a href="/microfrontend/" class="nav-link">微前端</a></div><div class="nav-item"><a href="/weixin/" class="nav-link">微信全家桶</a></div><div class="nav-item"><a href="/performance/" class="nav-link">性能优化</a></div><div class="nav-item"><a href="/log/" class="nav-link">每日随笔</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/introduce/" class="nav-link">指南</a></div><div class="nav-item"><a href="/sso/" class="nav-link">单点登录</a></div><div class="nav-item"><a href="/seo/" class="nav-link">服务端渲染</a></div><div class="nav-item"><a href="/linux/" class="nav-link">Linux基础</a></div><div class="nav-item"><a href="/http/" class="nav-link">解读Http</a></div><div class="nav-item"><a href="/microfrontend/" class="nav-link">微前端</a></div><div class="nav-item"><a href="/weixin/" class="nav-link">微信全家桶</a></div><div class="nav-item"><a href="/performance/" class="nav-link">性能优化</a></div><div class="nav-item"><a href="/log/" class="nav-link">每日随笔</a></div> <!----></nav>  <!----> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="网页爬虫的实现与注意事项"><a href="#网页爬虫的实现与注意事项" class="header-anchor">#</a> 网页爬虫的实现与注意事项</h1> <p>互联网每天都会产生非常多的信息，其中有不少的数据值得我们收集，我们往往是使用人工的方式去记录下来，但是我想说的是</p> <p>重复的事就应该交给电脑处理</p> <p>刚好前几天帮朋友做了一个爬虫小工具，借此机会把实现过程和注意事项分享一下</p> <ul><li>需求：通过上传Excel文件，读取Excel中的帖子链接，抓取帖子的 <code>标题，内容，图片个数，点击量和评论数</code></li></ul> <p>想到既然要做爬虫，第一考虑自然就是 <code>python</code> ， <em>详细见<a href="https://www.jianshu.com/p/52de49932327" target="_blank" rel="noopener noreferrer">《关于python模拟浏览器行为》<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></em> 。python天生对爬虫友好，利用 <code>requests和BeautifulSoup</code> 这两个模块，可以实现大部分的功能，但由于近期一直在做nodejs和项目，所以这里我们以 <code>nodejs</code> 为例。</p> <ul><li>目标：创建一个 <code>站点</code> ，接受用户 <code>上传</code> 的文件， <code>解析</code> 并实时 <code>爬取</code> 特定信息，保持数据到 <code>数据库</code> 中，并提供 <code>导出</code> 功能。</li></ul> <p><img src="https://upload-images.jianshu.io/upload_images/13908708-189f4ab2fdfb9313.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt="效果图"></p> <p><strong>实现过程</strong></p> <ul><li><code>需求分析</code></li></ul> <p>从上文中我们知道了大体需要实现 <code>导入excel、识别url、抓取url信息</code> 的功能。
既然要实现这种交互式的功能，做可执行程序或网站都是一个可行方案，从持续化更新角度出发，我们选用了开发web的方向，也就是搭建一个外网可访问的web站点。
其次， <code>导入excel</code> 涉及到_文件上传和io操作_，为了美观我们使用了 <code>Bootstrap</code> 框架做ui展示，后端使用 <code>nodejs</code> 接收文件。
接收到文件后，我们需要识别文件中的帖子url信息，这就需要我们去打开刚刚上传的文件了，这里使用npm模块 <code>XLSX</code> 去识别。
当读取完excel信息后，把url存放到队列中，通过在后端轮询队列发起http请求，不停爬取帖子信息，并实时通知前端页面当前进度和抓取内容，所以这里又用到了 <code>http/request</code> 和 <code>websocket</code> 。
抓取到信息后，还需要持久化，可以考虑记录到文本文件或数据库，这里选用数据库，所以还需要 <code>database</code> 相关。
最后，数据爬取完整后，提供一个导出功能，导出使用前端导出的方式，即生成table，调用第三方插件 <code>导出excel</code> 。</p> <ul><li><code>技术栈</code></li></ul> <table><thead><tr><th style="text-align:center;">技术</th> <th style="text-align:center;">版本</th> <th style="text-align:center;">描述</th></tr></thead> <tbody><tr><td style="text-align:center;">html</td> <td style="text-align:center;">5</td> <td style="text-align:center;">页面</td></tr> <tr><td style="text-align:center;">js</td> <td style="text-align:center;">ECMCScript2015</td> <td style="text-align:center;">脚本</td></tr> <tr><td style="text-align:center;">css</td> <td style="text-align:center;">3</td> <td style="text-align:center;">样式</td></tr> <tr><td style="text-align:center;">nodejs</td> <td style="text-align:center;">v10.15.1</td> <td style="text-align:center;">后端语言</td></tr> <tr><td style="text-align:center;">request</td> <td style="text-align:center;">v2.88.0</td> <td style="text-align:center;">http请求</td></tr> <tr><td style="text-align:center;">xlsx</td> <td style="text-align:center;">v0.14.3</td> <td style="text-align:center;">识别excel</td></tr> <tr><td style="text-align:center;">multiparty</td> <td style="text-align:center;">v4.2.1</td> <td style="text-align:center;">表单上传</td></tr> <tr><td style="text-align:center;">nodejs-websocket</td> <td style="text-align:center;">v1.7.2</td> <td style="text-align:center;">socket通讯</td></tr> <tr><td style="text-align:center;">jh-common-dataaccess</td> <td style="text-align:center;">v0.0.7</td> <td style="text-align:center;">数据库底层</td></tr> <tr><td style="text-align:center;">cheerio</td> <td style="text-align:center;">v1.0.0-rc.3</td> <td style="text-align:center;">html识别</td></tr> <tr><td style="text-align:center;">iconv-lite</td> <td style="text-align:center;">v0.5.0</td> <td style="text-align:center;">字符串编码</td></tr></tbody></table> <ul><li><code>数据来源</code></li></ul> <p>做爬虫程序，如何获取数据至关重要。在朋友给的参考页面上，需要获取到 <code>帖子标题、帖子内容、帖子图片数、评论数和点击数</code> 等，通过查看网络请求发现， <code>帖子标题、内容和图片</code> 是以 <code>html</code> 的形式展示，而 <code>评论数</code> 和 <code>点击数</code> ，需要额外发起异步请求获取，所以接下来的事就很明确了：</p> <ol><li>解析html内容，获取标题、内容和图片数</li> <li>研究评论数、点击数异步请求参数及数据结果</li></ol> <p>经研究后发现，html通过 <code>cheerio</code> 模块可以轻松识别</p> <div class="language-js extra-class"><pre class="language-js"><code><span class="token keyword">const</span> cheerio <span class="token operator">=</span> <span class="token function">require</span><span class="token punctuation">(</span><span class="token string">'cheerio'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">const</span> Iconv <span class="token operator">=</span> <span class="token function">require</span><span class="token punctuation">(</span><span class="token string">'iconv-lite'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">// body是html文档</span>
<span class="token keyword">const</span> $ <span class="token operator">=</span> cheerio<span class="token punctuation">.</span><span class="token function">load</span><span class="token punctuation">(</span>Iconv<span class="token punctuation">.</span><span class="token function">decode</span><span class="token punctuation">(</span>body<span class="token punctuation">,</span> <span class="token string">'gb2312'</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">let</span> titleTxt <span class="token operator">=</span> <span class="token function">$</span><span class="token punctuation">(</span><span class="token string">'#maxwrap-maintopic div.rconten'</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 帖子标题</span>
</code></pre></div><p>cheerio的使用和JQuery非常相像。</p> <p>而对于获取评论数和点击数却需要注意点细节，其中获取html的url中，会带有帖子的主键，查询点击数评论数的时候需要带上此信息，url如下</p> <div class="language- extra-class"><pre class="language-text"><code>https://xxx.xxx.com.cn/Detail/LoadX_Mini?topicId=帖子id
</code></pre></div><p>发起get请求后可以拿到 <code>replys</code> 和 <code>views</code> ，分别代表评论数和点击数。</p> <ul><li><code>数据处理</code></li></ul> <p>数据是从用户上传的excel中获取帖子url列表，通过表单上传和使用 <code>xlsx</code> 模块解析</p> <div class="language- extra-class"><pre class="language-text"><code>const XLSX = require('xlsx');
</code></pre></div><p>拿到需要爬取的帖子地址数组后，循环发起http请求，先获取html内容，再获取帖子评论数。发起http请求可以使用 <code>request</code></p> <div class="language- extra-class"><pre class="language-text"><code>const request = require('request');

// 配置参数
const options = {
		method: 'get',
		url: '目标url',
};
// 发起http请求
request(options, (err, res, body)=&gt;{
  // 解析body获取读取body信息
}};
</code></pre></div><p>由于需要向其他服务器发起请求，所以有很多事需要注意的，比如_ <code>如何避免反爬虫机制</code> _，后面会继续介绍。</p> <ul><li><code>数据持久化</code></li></ul> <p>获取到数据库，我们采用持久化到数据库的形式，我们之前就已经封装国一个数据库操作底层，支持mysql、mssql、sqlite等多种数据库操作，所以实现非常简单</p> <div class="language- extra-class"><pre class="language-text"><code>const { DataAccess } = require('jh-common-dataaccess');
const { dbConfig } = require('./package.json');

const ds = new DataAccess(dbConfig);
ds.execute('sql string');
</code></pre></div><ul><li><code>数据展示</code></li></ul> <p>既然是做web，那么自然需要做一个展示，我们通过html搭建了一个可视化界面，可以实时显示爬取进度和爬取操作，为了方便，封装了一个 <code>WebHelper</code> 和 <code>SocketHelper</code> ，分别提供web服务和socket服务。</p> <div class="language- extra-class"><pre class="language-text"><code>const WebHelper = require('./helper/WebHelper');
const SockeHelper = require('./helper/SocketHelper');

// socket服务
const socker = new SockeHelper();

// http服务
new WebHelper((req, res)=&gt;{
  // todo 处理响应
// 实时信息可通过socket进行广播
})
</code></pre></div><p><strong>注意事项</strong></p> <ol><li><p>注意字符编码，http响应的字符编码不一定符合要求，建议同意使用utf-8</p></li> <li><p>注意反爬虫机制。</p></li></ol> <p>与天斗与地斗与反爬虫斗，其乐无穷</p> <p>可以说做爬虫，不可避免要与反爬虫做斗争。
<code>第一次处理</code> ：在最开始做这个工具的时候，直接用多线程，循环很快就结束了，后台在不停的请求，测试后发现很快就返回500了，原因是目标服务器在短时间内接收到大量的请求，服务异常；
<code>第二次处理</code> ：使用递归模式，上一次请求完成后，等待一定时间再触发下一次请求，直到队列中没有需要爬取的url。这个方式基本解决了目标服务器奔溃的问题。然后一周的高频率爬取后，爬虫突然被限制，请求头中的信息被限制了
<code>第三次处理</code> ：修改请求头，随机选用 <code>User-Agent</code> 并使用 <code>代理ip</code> ，完美解决限制问题。
<code>第四次处理</code> ：发现其存在移动站点，且没加爬虫限制，决定分一半流量到其移动端站点。
<code>第五次处理</code> ：终究代理ip需要花钱，所以开发了一款谷歌插件，由客户端执行和服务端配合执行，形成最终结局方案。</p></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">1/13/2020, 3:59:17 PM</span></div></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.3328e81d.js" defer></script><script src="/assets/js/2.c715c0f2.js" defer></script><script src="/assets/js/56.63b1cb46.js" defer></script>
  </body>
</html>
